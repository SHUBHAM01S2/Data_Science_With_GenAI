{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6166b1",
   "metadata": {},
   "source": [
    "### 1. What is Simple Linear Regression?\n",
    "    - It’s a statistical method to model the linear relationship between one independent variable (X) and one dependent variable (Y) using a straight line.\n",
    "\n",
    "### 2. What are the key assumptions of Simple Linear Regression?\n",
    "    - Linearity: Relationship between X and Y is linear.\n",
    "    -Independence: Observations are independent.\n",
    "    -Homoscedasticity: Constant variance of residuals.\n",
    "    -Normality: Residuals are normally distributed.\n",
    "    -No or minimal multicollinearity (not usually relevant for simple regression).\n",
    "\n",
    "### 3. What does the coefficient m represent in the equation Y=mX+c?\n",
    "    - m is the slope of the line — it tells us how much Y changes for a unit increase in X.\n",
    "\n",
    "### 4. What does the intercept c represent in the equation Y=mX+c?\n",
    "    - c is the Y-intercept — the value of Y when X = 0.\n",
    "\n",
    "### 5. How do we calculate the slope m in Simple Linear Regression?\n",
    "    - m = n∑(xy) - ∑x∑y / nV(x^2) - (∑x)^2, Where n is number of observations\n",
    "\n",
    "### 6. What is the purpose of the least squares method in Simple Linear Regression?\n",
    "    - To find the best-fitting line by minimizing the sum of the squared differences (residuals) between observed and predicted Y values.\n",
    "\n",
    "### 7.  How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
    "    - It represents the proportion of variance in Y explained by X. R² = 0.8 → 80% of the variation in Y is explained by X.\n",
    "\n",
    "### 8. What is Multiple Linear Regression ? \n",
    "    - It models the relationship between one dependent variable and two or more independent variables.\n",
    "\n",
    "### 9. What is the main difference between Simple and Multiple Linear Regression?\n",
    "    - Simple: One independent variable. Multiple: Two or more independent variables.\n",
    "\n",
    "### 10. What are the key assumptions of Multiple Linear Regression?\n",
    "    - Linearity\n",
    "    - Independence of errors\n",
    "    - Homoscedasticity\n",
    "    - No multicollinearity\n",
    "    - Normal distribution of residuals\n",
    "\n",
    "### 11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model ?\n",
    "    - It’s when the residuals have non-constant variance, which can lead to inefficient estimates and biased standard errors.\n",
    "\n",
    "### 12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "    - Remove correlated predictors\n",
    "    - Use PCA (Principal Component Analysis)\n",
    "    - Apply Ridge or Lasso regression\n",
    "    - Combine correlated variables\n",
    "\n",
    "### 13. What are some common techniques for transforming categorical variables for use in regression models?\n",
    "    - 1. One-hot Encoding\n",
    "    - 2. Label Encoding (for ordinal data)\n",
    "    - 3. Dummy Variable Encoding.\n",
    "\n",
    "### 14. What is the role of interaction terms in Multiple Linear Regression ?\n",
    "    - Interaction terms (e.g., X1 * X2) capture combined effects of two or more variables on the target, revealing non-additive relationships.\n",
    "\n",
    "### 15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "    - Simple Linear Regression : Y when X = 0\n",
    "    - Multiple Linear Regression : Y when all independent variables = 0 (which may not be meaningful)\n",
    "\n",
    "### 16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "    - It shows the rate of change in Y with respect to X. A significant slope implies a strong linear relationship.\n",
    "\n",
    "### 17. How does the intercept in a regression model provide context for the relationship between variables?\n",
    "    - It sets a baseline value for Y when all X variables are zero. It helps understand the starting point of the model.\n",
    "\n",
    "### 18. What are the limitations of using R² as a sole measure of model performance ?\n",
    "    - Doesn’t indicate causation\n",
    "    - Can be artificially high with many variables\n",
    "    - Doesn’t account for overfitting (adjusted R² is better for multiple variables)\n",
    "\n",
    "### 19. How would you interpret a large standard error for a regression coefficient ?\n",
    "    - Indicates high uncertainty or variability in the estimate — the coefficient might not be statistically significant.\n",
    "\n",
    "### 20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "    - In residual vs. fitted value plots: If spread increases/decreases → heteroscedasticity. Important to fix because it violates regression assumptions.\n",
    "\n",
    "### 21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
    "    - Suggests that irrelevant variables are included in the model. Adjusted R² penalizes unnecessary predictors.\n",
    "\n",
    "### 22. Why is it important to scale variables in Multiple Linear Regression?\n",
    "    - To ensure all variables contribute equally. Especially important for models involvinf regularization or interaction terms.\n",
    "\n",
    "### 23. What is polynomial regression ?\n",
    "    - It extends linear regression by allowing nonlinear relationships using polynomial terms (e.g., X^2, X^3).\n",
    "\n",
    "### 24. How does polynomial regression differ from linear regression ?\n",
    "    - Linear: Predicts Y using straight line.\n",
    "    - Polynomial: Fits a curved line to capture nonlinearity.\n",
    "\n",
    "### 25. When is polynomial regression used?\n",
    "    - When the relationship between X and Y is nonlinear but smooth and continuous.\n",
    "\n",
    "### 26. What is the general equation for polynomial regression?\n",
    "    - Y = B0 + B1X + B2X^2 + ... + BnX^n + e.\n",
    "\n",
    "### 27. Can polynomial regression be applied to multiple variables?\n",
    "    - Yes, but becomes multivariate polynomial regression — adds cross-product and higher-order terms for each variable.\n",
    "\n",
    "### 28. What are the limitations of polynomial regression ?\n",
    "    - Prone to overfitting. \n",
    "    - Harder to interpret\n",
    "    - High-degree polynomials can oscillate widely (Runge's phenomenon)\n",
    "\n",
    "### 29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "    - Adjusted R^2\n",
    "    - Cross-Validation\n",
    "    - AIC/BIC (information criteria)\n",
    "\n",
    "### 30. Why is visualization important in polynomial regression ?\n",
    "    - Helps detect overfitting, underfitting, and the nature of nonlinearity. Curves can be visualized to understand fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb4cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [ 1.  4.  9. 16. 25.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Input data\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "y = np.array([1, 4, 9, 16, 25])\n",
    "degree = 2\n",
    "# Create model pipeline\n",
    "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "# Predict\n",
    "y_pred = model.predict(X)\n",
    "print(\"Predictions:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849111b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
